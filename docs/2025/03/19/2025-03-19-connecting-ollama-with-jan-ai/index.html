<!DOCTYPE html>
<html>
    
    <head>
    <title>How to connect Jan.ai to Ollama(non-.cpp)</title>
    <meta charset="UTF-8" />

    <link rel="stylesheet" href="/static/css/style.css" />
    <!-- <link rel="stylesheet" href="/css/typebase.css"> -->
    <link
        href="https://unpkg.com/basscss@8.0.2/css/basscss.min.css"
        rel="stylesheet"
    />

    <link
        rel="stylesheet"
        href="/static/3rdparty/highlight/styles/dark.min.css"
    />
    <script src="/static/3rdparty/highlight/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>

    <script defer src="https://umami.taylorbrazelton.com/script.js" data-website-id="bae6a05d-d545-4d68-9810-f6e03a2965e0"></script>

    <script type="module">
        import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
        mermaid.initialize({ startOnLoad: true });
    </script>

    <script type="text/javascript">
        (function (c, l, a, r, i, t, y) {
            c[a] =
                c[a] ||
                function () {
                    (c[a].q = c[a].q || []).push(arguments);
                };
            t = l.createElement(r);
            t.async = 1;
            t.src = "https://www.clarity.ms/tag/" + i;
            y = l.getElementsByTagName(r)[0];
            y.parentNode.insertBefore(t, y);
        })(window, document, "clarity", "script", "molkkkznzg");
    </script>
</head>

    <body>
        <nav>
    <ul>
        <li><a href="/">Home</a></li>
        
        <li><a href="/about/">About</a></li>
        
        <li><a href="/creations/">Creations</a></li>
        
        <li><a href="/tools/">Tools</a></li>
        
    </ul>
</nav>

        <h1>How to connect Jan.ai to Ollama(non-.cpp)</h1>
        <div class="post-body">
            <p>Running LLMs locally is great for privacy and olline access.</p>
<p>My current setup is to use Jan.ai and Ollama. However, instructions on this setup seem to elude others, so I figure I'd share how I did it.</p>
<p>Since Jan.AI works with OpenAI compatible APIs. You can hook them up by creating a new Engine.</p>
<ol>
<li>Open Jan</li>
<li>Click the settings icon in the lower left corner.</li>
<li>Under "General" select the "Engines" tab.</li>
<li>Select "Install Engine" and fill out the following details, leaving any extra fields blank.
Engine Name: Ollama
Chat Completions URL: http://localhost:11434/v1/chat/completions
Model List URL: http://localhost:11434/v1/models
API Key: ollama</li>
<li>Click "Install"</li>
</ol>
<p>Now when you create a new thread, you should be able to select "Ollama" from the cloud tab, and then select the pre-downloaded model from the list.</p>
<p>Enjoy!</p>

        </div>
        <hr />
        <p>Posted on 2025-03-19</p>
    </body>
</html>